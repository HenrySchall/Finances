# S√©ries Temporais
Modelos de s√©ries temporais

    ARIMA, GARCH, EGARCH, TGARCH ‚Äì previs√µes de retornos ou volatilidade.
    VAR / SVAR / Bayesian VAR ‚Äì analisar intera√ß√µes entre v√°rios ativos ou vari√°veis macroecon√¥micas.
    Modelos de alta frequ√™ncia (ex.: modelos de ponto de ocorr√™ncia) ‚Äì para dados intradi√°rios.


> Uma s√©rie temporal √© um conjunto de observa√ß√µes ordenadas em ordem cronol√≥gica no tempo ou um processo estoc√°stico desconhecido. Matematicamente: Y = Tdt + Szt + et.

covariacia x corrrela√ß√£o

* Tend√™ncia (Tdt): Mudan√ßas graduais no longo prazo (crescimento populacional).
* Sazonalidade (Szt): oscila√ß√µes para cima e para baixo que sempre ocorrem em um determinado per√≠odo (contas de luz mais altas no inverno).
* Res√≠duos (et): mostram os movimentos para cima e para baixo na s√©rie ap√≥s a remo√ß√£o da tend√™ncia ou do efeito sazonal (sequ√™ncia de vari√°veis aleat√≥rias).

(IMAGEM)

> As S√©ries temporais podem ser usadas para fazer previs√µes futuras, descrever o comportamento serial de um vari√°vel, analisar periodicidade, tend√™ncias ou at√© mesmo definir o processo gerador de uma s√©rie. Elas podem ser divididas em dois tipos:-
- Vari√°veis
- Univariadas = apenas uma vari√°vel muda ao longo do tempo
- Multivariadas = mais de uma vari√°vel muda ao longo do tempo

- Tempo
- Unidimensuiioaonsi somente a vria¬¥vel tempom envolvio
- Multidimensioanis -> outras vria¬¥vesi asspociadas ao tempo

### Conceitos B√°sicos 
> Processo Estoc√°stico -> √â uma cole√ß√£o de vari√°veis aleat√≥rias definidas no mesmo espa√ßo de probabilidade (processo que gera uma s√©rie de vari√°veis). A descri√ß√£o de um processo estoc√°stico √© feita por meio de uma distribui√ß√£o de probabilidade conjunta (o que √© muito complexo de fazer), ent√£o geralmente o descrevemos por meio das fun√ß√µes:
- $ùúá(ùë°)=ùê∏{ùëç(ùë°)}$ -> M√©dia
- $ùúé^2(ùë°)=ùëâùëéùëü{ùëç(ùë°)}$ -> Vari√¢ncia
- $ùõæ(ùë°1,ùë°2)=ùê∂ùëúùë£{ùëç(ùë°1),ùëç(ùë°2)}$ -> Autocovari√¢ncia

![Img1](https://github.com/user-attachments/assets/4f5af5b4-917b-4c5a-97ac-45166549dcbe)

> Ru√≠do Branco -> √© quando o erro de uma s√©rie temporal segue uma distribui√ß√£o normal, ou seja, um processo puramente aleat√≥rio.
- E(Xt)=0
- Var(Xt)=ùúé2

> Passeio Aleat√≥ria (Random Walk) -> √© a soma de pequenas flutua√ß√µes estoc√°sticas (tend√™ncia estoc√°stica). Matematicamente: ùëçùë° = ùëç(ùë°‚àí1) + et

(IMAGEM)

> Autocorrela√ß√£o -> √© a correla√ß√£o de determinados per√≠odos anteriores com o per√≠odo atual, ou seja, o grau de depend√™ncia serial. Cada per√≠odo desse tipo de correla√ß√£o √© chamado de defasagem e sua representa√ß√£o √© feita pela Fun√ß√£o de Autocorrela√ß√£o (ACF) e pela Fun√ß√£o de Autocorrela√ß√£o Parcial (PAF), ambas comparando o valor presente com os valores passados da s√©rie. A diferen√ßa entre elas √© que a CAF analisa tanto a correla√ß√£o direta quanto a indireta, enquanto a PAF analisa apenas a correla√ß√£o direta. Ent√£o, podemos dizer que a CAF v√™ a correla√ß√£o direta do m√™s de janeiro com o de mar√ßo e tamb√©m a correla√ß√£o indireta que o m√™s de janeiro teve com o de fevereiro, que tamb√©m teve com o de mar√ßo, enquanto a PAF apenas a correla√ß√£o de janeiro com o de mar√ßo. Essa an√°lise √© feita por ser a premissa essencial para a cria√ß√£o de previs√µes eficientes de uma s√©rie.

> Estacionariedade -> √â quando uma s√©rie temporal apresenta todas as suas caracter√≠sticas estat√≠sticas constantes ao longo do tempo, ou seja, n√£o mudam de comportamento (inclina√ß√£o e mudan√ßa de n√≠vel)

(IMAGEM)
 
 Tipos 
 - Estacionariedade Forte = tamb√©m chamada de estacionariedade estrita, ocorre quando as distribui√ß√µes unidimensionais s√£o invariantes ao longo do tempo, ou seja, as distribui√ß√µes individuais s√£o as mesmas para todos os "ts". Portanto, a covari√¢ncia depende apenas da dist√¢ncia entre as observa√ß√µes e n√£o do momento espec√≠fico em que ocorreram.
 - Estacionariedade Fraca = √â quando as propriedades estat√≠sticas s√£o est√°veis apenas na M√©dia E(x) = U, Vari√¢ncia Var(x) = ùúé¬≤ e na Covari√¢ncia COV(X,X-n) = k, ou seja, estabilidade de segunda ordem. Na pr√°tica estacionariedade geralmente significa estacionariedade fraca porque muitos m√©todos dependem apenas de momentos de ordem 1 e 2.


















![plot](https://github.com/user-attachments/assets/6cde76a5-8419-4d3c-b32b-1630c27b36a5)

> Time series studies can be used for future predictions, description of serial behavior, and analysis of periodicity, trends, or even the process that generates the series. They are divided into two types:

- Univariate = only one variable changes over time
- Multivariate = more than one variable changes over time****

### Initial Concepts

> Stochastic Process -> is a collection of random variables defined in the same probability space (process generating a series of variables). The description of a stochastic process is done through a joint probability distribution (which is very complex to do), so we usually describe it through the functions:
- $ùúá(ùë°)=ùê∏{ùëç(ùë°)}$ -> Average
- $ùúé^2(ùë°)=ùëâùëéùëü{ùëç(ùë°)}$ -> Variance 
- $ùõæ(ùë°1,ùë°2)=ùê∂ùëúùë£{ùëç(ùë°1),ùëç(ùë°2)}$ -> Autocovariance

![estocastico](https://github.com/user-attachments/assets/d1a7faa1-0cad-46f2-bf2c-b369e13209c2)

> Stationarity -> is when a time series presents all its statistical characteristics constant over time

- Weak Stationarity = when the statistical properties are constant over time, E(x) = U, Var(x) = ùúé¬≤, COV(X,X-n) = k (covariance between observations at different points in time depends on the specific time at which they occurred). In the literature, stationarity generally means weak stationarity.
- Strong Stationarity = also called strict stationarity, is when the joint probability function is invariant over time, that is, the individual distributions are the same for all "ts". Therefore, the covariance depends only on the distance between the observations and not on the specific time at which they occurred.

> Autocorrelation -> is the correlation of certain previous periods with the current period, that is, the degree of serial dependence. Each period of this type of correlation is called lag and its representation is made by the Autocorrelation Function (ACF) and the Partial Autocorrelation Function (PAF), both of which compare the present value with the past values ‚Äã‚Äãof the series. The difference between them is that the CAF analyzes both direct and indirect correlation, while the PAF only analyzes direct correlation. So we can say that the CAF sees the direct correlation of the month of January in March and also the indirect correlation that the month of January had in February, which also had in March, while the PAF only the correlation of January in March. This analysis is done because it is the essential assumption for creating efficient forecasts of a series.

![FAC](https://github.com/user-attachments/assets/4623a946-6427-4bc2-aadc-d8219df93db9)

![FACP](https://github.com/user-attachments/assets/9d577631-0da2-4101-b695-cfa4f35d2fc5)

> White Noise -> is when the error of a time series follows a normal distribution, that is, a purely random process.
- E(Xt)=0
- Var(Xt)=ùúé2

![Captura de tela 2025-01-30 132421](https://github.com/user-attachments/assets/0fbabff6-f692-48ad-bc84-bea27f7f30ae)

> Random Walk -> is the sum of small stochastic fluctuations (stochastic trend). Mathematically: ùëçùë°=ùëç(ùë°‚àí1)+et

![Captura de tela 2025-01-30 132324](https://github.com/user-attachments/assets/bf7ce3a1-560b-45ad-9d1c-459cea90fe26)

> Transformation and Smoothing -> These are techniques that seek to make the series as close as possible to a normal distribution. Transforming the value of the variables or smoothing the trend and/or seasonality of the series. Among all the existing techniques we can mention:

1) Log Transformation
2) Exponential Transformation
3) Box-Cox Transformation
4) Exponential Moving Average Smoothing (EMA) - Short-term
5) Simple Moving Average Smoothing (SMA) - Long-term

> Differentiation -> Differentiation seeks to transform a non-stationary series into a stationary one, by means of the difference of two consecutive periods

![Sem T√≠tulo-1](https://github.com/user-attachments/assets/390abc00-d4aa-41bf-be96-6ec3eeaf7684)

#### Univariate time series models:
Linear models:
- Autoregressive models (AR)
- Moving average models (MA)
- Autoregressive and moving average models (ARMA)
- Autoregressive integrated and moving average models (ARIMA)
- Long time dependency or long memory models (ARFIMA)
- Autoregressive integrated and moving average models with seasonality (SARIMA)

Nonlinear models:
- Autoregressive with threshold (TAR)
- Autoregressive with smooth transition (STAR)
- Markov regime switching (MSM)
- Autoregressive artificial neural networks (AR-ANN)

Structure:
- Autoregressive (AR): indicates that the variable is regressed on its previous values.
- Integrated (I): indicates that the data values ‚Äã‚Äãwere replaced with the difference between their values ‚Äã‚Äãand the previous values ‚Äã‚Äã(differencing).
- Moving average (MA): Indicates that the regression error is a linear combination of the error terms of the past values.
- 
Coding: (p, d, q) Parameter d can only be an integer, if we were working with an ARFIMA Model, the parameter d can be fractional
- p = order of autoregression.
- d = degree of differentiation.
- q = order of the moving average.

> When we add seasonality, in addition to the Arima coding (p, d, q), we include the coding for Seasonality (P, D, Q). Then a SARIMA model is defined by: (p, d, q)(P, D, Q)
Examples:

- ARFIMA model: (1, 0.25, 1)
- ARIMA model: (2, 1, 1)
- AR model: (1, 0, 0)
- MA model (0, 0, 3)
- I model: (0, 2, 0)
- ARMA model: (4, 0, 1)
- SARIMA model: (1, 1, 2)(2, 0, 1)

Akaike's Information Criterion (AIC) and the Bayesian Information Criterion (BIC)
> In more advanced models, the autocorrelation and partial autocorrelation functions are not informative for defining the order of the models, so an information criterion is used. An information criterion is a way of finding the ideal number of parameters for a model. To understand it, keep in mind that, with each additional regressor, the sum of the residuals will not increase; it will often decrease. The reduction occurs at the cost of more regressors. To balance the reduction in errors and the increase in the number of regressors, the information criterion associates a penalty with this increase. Therefore, its equation has two parts: the first measures the quality of the model's fit to the data, while the second part is called the penalty function since it penalizes models with many parameters. Therefore, given all the combinations of models, we look for the one with the lowest AIC.







#### Testes Estat√≠sticos

##### Teste de Kolmogorov-Smirnov
> Qualifica a m√°xima diferen√ßa absoluta entre a fun√ß√£o de distribui√ß√£o da amostra e a fun√ß√£o de distribui√ß√£o acumulada da distribui√ß√£o de refer√™ncia (geramente distribui√ß√£o normal), ou seja, ele qualifica dist√¢ncia entre duas amostras (compara√ß√£o entre elas).

- *H0: A amostra segue a distribui√ß√£o de refer√™ncia*
- *H1: A amostra n√£o segue a distribui√ß√£o de refer√™ncia*

##### Teste de Anderson-Darling 
> Testa se uma fun√ß√£o de distribui√ß√£o acumulada f(x), pode ser candidata a ser um fun√ß√£o de distribui√ß√£o acumulada de uma amostra aleat√≥ria;

- *H0: A amostra tem distribui√ß√£o de f(x)*
- *H1: A amostra n√£o tem distribui√ß√£o f(x)*

##### Teste de Shapiro Wilk 
> O teste Shapiro Wilk segue a seguinte equa√ß√£o descrita abaixo. Sendo que xi s√£o os valores da amostra ordenados, no qual valores menores que W s√£o evid√™ncias de que os dados s√£o normais.

![Captura de tela 2024-07-04 191812](https://github.com/HenrySchall/Time-Series/assets/96027335/c9789639-2602-44bb-a9f3-491b92b65310)

> J√° o termo b √© determinado pela seguinte equa√ß√£o:

![Captura de tela 2024-07-04 192115](https://github.com/HenrySchall/Time-Series/assets/96027335/c2594f21-082f-4f6d-9293-66b45b0125fb)

> onde ai s√£o constantes geradas pelas m√©dias, vari√¢ncias e covari√¢ncias das estat√≠sticas de ordem de uma amostra de tamanho n de uma distribui√ß√£o normal (tabela da normal).

Estat√≠stica de teste:
- *H0: A amostra segue uma distribui√ß√£o normal (W-obtido < W-cr√≠tico)*
- *H1: A amostra n√£o segue uma distribui√ß√£o normal (W-obtido > W-cr√≠tico)*

![img46](https://github.com/HenrySchall/Time-Series/assets/96027335/64ca5aa1-d601-44b1-8d21-16ec79400211)

##### Teste de Jarque-Bera
> Verifica se os erros s√£o um Ru√≠do Branco, ou seja, seguem uma distribui√ß√£o normal. O teste se baseia nos res√≠duos do m√©todo dos m√≠nimos quadrados. Para sua realiza√ß√£o o teste necessita dos c√°lculos da assimetria (skewness) e da curtose (kurtosis) da amostra, dado pela seguinte f√≥rmula:
 
![Captura de tela 2024-07-04 193133](https://github.com/HenrySchall/Time-Series/assets/96027335/fe76cc80-fa40-46c8-8357-7e19e49339a5)

> onde n e o n√∫mero de observa√ß√µes (ou graus de liberdade geral); S √© aassimetria da amostra; e K √© a curtose da amostra

![Captura de tela 2024-07-04 193243](https://github.com/HenrySchall/Time-Series/assets/96027335/b24d6ca3-6e20-44ed-a3d6-5004c3646bd6)

$\widehat{u3}$ e $\widehat{u4}$ s√£o as estimativas do terceiro e quarto momentos, respectivamente; $\bar{x}$ a m√©dia da amostra, e $ùúé^2$ √© a estimativa do segundo momento, a vari√¢ncia.

- *H0: res√≠duos s√£o normalmente distribu√≠dos*
- *H1: res√≠duos n√£o s√£o normalmente distribu√≠dos*

#### Resumo:

|Teste|Quando usar|Pr√≥s|Contras|Cen√°rios n√£o indicados|
|---|---|---|---|---|
|Shapiro-Wilk|Pequenas amostras (sens√≠vel a pequenas desvios da normalidade)|Sens√≠vel a pequenas desvios da normalidade (adequado para amostras pequenas|Pode ser menos potente em amostras maiores|Dados com distribui√ß√£o fortemente bimodal ou multimodal|
|Kolmogorov-Smirov|Amostras grandes (teste n√£o param√©trico)|N√£o requer suposi√ß√µes sobre os par√¢metros da distribui√ß√£o (adequado para amostras grandes)|Menos sens√≠vel a pequenos desvios (menos potente em amostras pequenas)|Sens√≠vel a desvios nas caudas da distribui√ß√£o|
|Anderson Darling|Verifica√ß√£o geral de normalidade|Sensibilidade a desvios em caudas e simetria (fornece estat√≠stica de teste e valores cr√≠ticos)|Menos sens√≠vel a desvios pequenos|N√£o √© recomendado para amostras muito pequenas|
|Jaque-Bera|Verifica√ß√£o geral de normalidade em amostras grandes|Combina informa√ß√µes sobre simetria e curtose (adequado para amostras grandes)|Menos sens√≠vel a desvios pequenos|Sens√≠vel a desvios nas caudas da distribui√ß√£o| 
  
##### Teste de Ader√™ncia
> Este teste √© utilizado quando deseja-se validar a hip√≥tese que um conjunto de dados √© gerado por uma determinada distribui√ß√£o de probabilidade.

- *H0: segue o modelo proposto*
- *H1: n√£o segue o modelo proposto*
  
##### Teste de Indeped√™ncia
> Este teste √© utilizado quando deseja-se validar a hip√≥tese de independ√™ncia entre duas vari√°veis aleat√≥rias. Se por exemplo, existe a funl√ßao de probabilidade conjunta das duas vari√°veis aleat√≥rias, pode-se verificar se para todos os poss√≠veis valores das vari√°vies, o produto das probabilidades margianis √© igual √† probabilidade conjunto.

- *H0: as vari√°veis aleat√≥rias s√£o independentes*
- *H1: as vari√°veis aleat√≥rias n√£o s√£o independentes*

##### Teste de Homogeneidade
> Esse teste √© utilizado quando deseja-se validar a hip√≥tese de que uma vari√°vel aleat√≥ria apresenta comportamento similar, ou homog√™neo, em rela√ß√£o √†s suas v√°rias subpopula√ß√µes. Este teste apresenta a mesma mec√¢nica do Teste de Independ√™ncia, mas uma distin√ß√£o importante se refere √† forma como as amostras s√£o coletadas. No Teste de homogeneidade fixa-se o tamanho da amostra em cada uma das subpopula√ß√µes e, ent√£o, seleciona-se uma amostra de cada uma delas.

- *H0: As subpopula√ß√µes das vari√°veis aleat√≥rias s√£o homog√™neas*
- *H1: As subpopula√ß√µes das vari√°veis aleat√≥rias n√£o s√£o homog√™neas*

#### Coeficientes de Correla√ß√£o
> Os coeficientes de correla√ß√£o verificam a exist√™ncia e o grau de associa√ß√£o entre dois conjuntos de dados.

##### Coeficiente Pearson 
> Estabelecer o n√≠vel de rela√ß√£o linear entre duas vari√°veis. Em outras palavras, mede em grau e o sentido (crescente/decrescente) da associa√ß√£o linear entre duas vari√°veis. Ele sempre estar√° entre ‚àí1,00 e +1,00, tendo o sinal a fun√ß√£o de indicar a dire√ß√£o do movimento, ou seja, positivo (rela√ß√£o direta) e negativa (rela√ß√£o inversa) e o valor do coeficiente, a fun√ß√£o de indicar a for√ßa da correla√ß√£o, onde nos intervalos:
> - (+0,90; +1,00) ou (‚àí1,00; ‚àí0,90) = correla√ß√£o muito forte
> - (+0,60; +0,90) ou (‚àí0,90; ‚àí0,60) = correla√ß√£o forte
> - (+0,30; +0,60) ou (‚àí0,60; ‚àí0,30) = correla√ß√£o moderada
> - (0,00; +0,30) ou (‚àí0,30; 0,00) = correla√ß√£o fraca
>
> Graficamente:

![3](https://github.com/HenrySchall/Time-Series/assets/96027335/5391579e-90f0-4ed2-92a0-b95c6068591f)

> Sua equa√ß√£o √© definida pela seguinte f√≥rmula:

![1](https://github.com/HenrySchall/Time-Series/assets/96027335/8f4dd7f6-e82b-4bf0-a06d-58400ede1060)

> Lembrando que o coeficiente de correla√ß√£o populacional √© dado por:

![2](https://github.com/HenrySchall/Time-Series/assets/96027335/6e39a2b7-4bfd-4d30-987e-bca3e8c5c8d8)

> Exemplo: A tabela abaixo apresenta 15 observa√ß√µes, com o tempo de entrega (em minutos) e a dist√¢ncia de entrega de um TelePizza.

|Tempo|Dist√¢ncia|
|---|---|
|40|688|
|21|215|
|14|255|
|20|462|
|24|448|
|29|776|
|15|200|
|19|132|
|10|36|
|35|770|
|18|140|
|52|810|
|19|450|
|20|635|
|11|150|

> Calculando os valores obtemos o seguinte resultado:

![4](https://github.com/HenrySchall/Time-Series/assets/96027335/a224016f-5d0a-4b84-ac79-6b8f5dae6ae1)

> Conclui-se que existe uma rela√ß√£o linear forte e positiva entre as vari√°veis. Todavia o coeficiente de correla√ß√£o de Pearson √© apenas uma estimativa do coeficiente de correla√ß√£o populacional, pois √© calculado com base em uma amostra aleat√≥ria de ùëõ pares de dados. Sendo assim a amostra observada pode apresentar correla√ß√£o, mas a popula√ß√£o n√£o, neste caso, tem-se um problema de infer√™ncia, pois o fato de r‚â†0 n√£o √© garantia de ùúå‚â†0. Para resolver esse problema, utiliza-se da estat√≠stica de teste T-student, definido pela equa√ß√£o abaixo, para verificar se realmente existe correla√ß√£o linear entre as vari√°veis:

![5](https://github.com/HenrySchall/Time-Series/assets/96027335/84310f44-b3d8-477d-9e71-1ec81dcbb21a)

> Onde ùë° segue uma distribui√ß√£o ùë°‚àíùëÜùë°ùë¢ùëëùëíùëõùë° com ùëõ‚àí2 graus de liberdade e regido pelas seguintes hip√≥teses:

- *H0: A correla√ß√£o entre as vari√°veis √© zero (ùúå = 0)*
- *H1: A correla√ß√£o entre as vari√°veis n√£o √© zero (ùúå ‚â† 0)*

![6](https://github.com/HenrySchall/Time-Series/assets/96027335/ccc5a428-cea3-4a8f-a773-c6b454b87f28)

> A partir da estat√≠stica ùë° com 13 graus de liberdade, os pontos cr√≠ticos s√£o ¬±2,1604. Portanto, rejeita-se ùêªùëú ao n√≠vel de signific√¢ncia de 5%. Sendo assim a correla√ß√£o entre o tempo de entrega e a dist√¢ncia percorrida √© diferente de zero, ent√£o, existe uma rela√ß√£o linear e positiva entre as vari√°veis da ordem de ùëü = 0,8216.

##### Coeficiente Spearman
> O coeficiente de correla√ß√£o de Spearman, ou rho de Spearman, √© uma medida n√£o param√©trica da correla√ß√£o (associa√ß√£o) entre duas vari√°veis ordinais. Ao contr√°rio do coeficiente de correla√ß√£o de Pearson, que mede a for√ßa e a dire√ß√£o da rela√ß√£o linear entre duas vari√°veis, o coeficiente de Spearman avalia a intensidade (o qu√£o bem) √© a rela√ß√£o entre duas vari√°veis. O coeficiente de correla√ß√£o de Spearman (ùúå) √© calculado utilizando a seguinte f√≥rmula:

![20](https://github.com/HenrySchall/Time-Series/assets/96027335/65f56f8e-31b3-4d4f-a4d0-b7e692b2fd44)

#### Interpreta√ß√£o:
- œÅ=1 indica uma perfeita correla√ß√£o positiva.
- œÅ=‚àí1 indica uma perfeita correla√ß√£o negativa.
- œÅ=0 indica aus√™ncia de correla√ß√£o.

> Exemplo: Dados os valores da tabela abaixo:

![9](https://github.com/HenrySchall/Time-Series/assets/96027335/68db17b8-2b31-41c9-b1d1-cf241b30ee55)

> Calculando os valores obtemos o seguinte resultado:

![12](https://github.com/HenrySchall/Time-Series/assets/96027335/1c332788-5570-48e1-8d17-2b3b36c61aff)
 
> Utilizando-se da mesma equa√ß√£o estat√≠stica do teste T-student. Teremos as seguintes hip√≥teses:

- *H0: A correla√ß√£o entre as vari√°veis √© zero*
- *H1: A correla√ß√£o entre as vari√°veis n√£o √© zero*

> A partir da estat√≠stica ùë°‚àíùëÜùë°ùë¢ùëëùëíùëõùë° com 11 graus de liberdade, os pontos cr√≠ticos s√£o ¬±2,2010. Portanto, rejeita-se ùêªùëú ao n√≠vel de signific√¢ncia de 5%. Sendo assim a correla√ß√£o entre as vari√°veis ùëã e ùëå √© diferente 
de zero, ent√£o, existe uma rela√ß√£o n√£o-linear e negativa de ordem ùëü= ‚àí0,9698. 

##### Coeficiente Kendall 
> O coeficiente de correla√ß√£o de Kendall √© uma medida estat√≠stica utilizada para avaliar a associa√ß√£o entre duas vari√°veis ordinais, exatamente igual ao coeficiente de correla√ß√£o de Spearman, a difenre√ßa √© que ele mede a correla√ß√£o de concord√¢ncia, enquanto Spearman, mede a correla√ß√£o de postos. Sendo particularmente √∫til quando as vari√°veis em quest√£o n√£o assumem necessariamente distribui√ß√µes normais. O coeficiente de correla√ß√£o de Kendall (œÑ) √© definido pela seguinte f√≥rmula:

![124](https://github.com/HenrySchall/Time-Series/assets/96027335/ac68ba9a-1c0d-4cab-a892-7d9ab87cc400)

> No qual, ùëõ √© o n√∫mero de elementos aos quais atribui-se postos, ùëÜ √© a soma da vari√°vel ùëå √† direita que s√£o superiores menos o n√∫mero de postos √† direita que s√£o inferiores.

#### Interpreta√ß√£o:
- œÑ=1 indica uma perfeita concord√¢ncia.
- œÑ=‚àí1 indica uma perfeita discord√¢ncia.
- œÑ=0 indica aus√™ncia de associa√ß√£o entre as vari√°veis.

> Para o c√°lculo do coeficiente de correla√ß√£o por postos de Kendall ordena-se inicialmente uma das vari√°veis em ordem crescente de postos e o S correspondente a cada elemento ser√° obtido fazendo o n√∫mero de elementos 
cujo posto √© superior ao que se est√° calculando menos o n√∫mero de elementos cujo posto √© inferior ao mesmo. Para verificar a signific√¢ncia do valor observado do coeficiente ùúè de Kendall, para ùëõ‚â§10 deve-se consultar a tabela abaixo.

![125](https://github.com/HenrySchall/Time-Series/assets/96027335/9a2f16b5-e667-4d3c-a8dd-01d3ed678409)

> Para ùëõ>10, pode utilizar a estat√≠stica de teste:

![128](https://github.com/HenrySchall/Time-Series/assets/96027335/275d3eda-ef7e-453a-86d1-a4918ef935ff)

> Exemplo: Dados os valores da tabela abaixo:



> Calculando os valores obtemos o seguinte resultado:



> Tendo as seguintes hip√≥teses:

- *H0: A correla√ß√£o entre as vari√°veis √© zero (ùúè=0)*
- *H1: A correla√ß√£o entre as vari√°veis n√£o √© zero (ùúè‚â†0)*

>  A partir da estat√≠stica ùëÅùëúùëüùëöùëéùëô ùëùùëéùëëùëü√£ùëú, os pontos cr√≠ticos s√£o ¬±1,96. Portanto, rejeita-se ùêªùëú ao n√≠vel de signific√¢ncia de 5%. Sendo assim a correla√ß√£o entre as vari√°veis ùëã e ùëå √© diferente de zero, ent√£o, existe uma 
rela√ß√£o n√£o-linear e negativa de ordem ùúè=‚àí0,7692.

*Observa√ß√£o: Pode-se fazer uma compara√ß√£o entre coeficiente de correla√ß√£o de Spearman e o coeficiente de correla√ß√£o por postos de Kendall. Os valores num√©ricos n√£o s√£o iguais, quando calculados para os mesmos pares de postos, e n√£o s√£o compar√°veis numericamente. Contudo, pelo fato de utilizarem a mesma quantidade de informa√ß√£o contida nos dados, ambos t√™m o mesmo poder de detectar a exist√™ncia de associa√ß√£o na popula√ß√£o, e rejeitar√£o a hip√≥tese nula para um mesmo n√≠vel de signific√¢ncia.*


############################
### Holt-Winters Aditivo ###
############################

from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt

# PremierPet
Produto = 4002
serie = df[df['Produto'] == Produto][['Datetime', 'Quantidade']].copy()
serie.set_index('Datetime', inplace=True)

# Ajusta o modelo
fit1 = ExponentialSmoothing(
    serie,
    trend='additive',
    damped_trend = False,
    seasonal='additive',
    seasonal_periods=12,
).fit()

forecast = fit1.forecast(12)
print(forecast)

# Valores Passados
fit1.fittedvalues.plot(style='--', color='red')
plt.show()

# Valores Futuros
fit = 12 # meses futuros
fit1.forecast(fit).plot(style='--', marker='o', color='black', legend=True)
plt.show()

# Agrupando tudo em um gr√°fico
forecast_h = 12  # meses futuros
forecast = fit1.forecast(forecast_h)

plt.plot(serie, label='Observado', color='blue')
plt.plot(fit1.fittedvalues, '--', label='Ajustado', color='red')
plt.plot(forecast, '--o', label='Previs√£o', color='black')
plt.xlabel('Data')
plt.ylabel('Quantidade')
plt.title(f'Previs√£o Holt-Winters - Produto {Produto}')
plt.legend()
plt.grid(True)
plt.show()

###################################
### Holt-Winters Multiplicativo ###
###################################

from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt

# PremierPet
Produto = 4002
serie = df[df['Produto'] == Produto][['Datetime', 'Quantidade']].copy()
serie.set_index('Datetime', inplace=True)

# Ajusta o modelo
fit2 = ExponentialSmoothing(
    serie,
    trend='multiplicative',
    damped_trend = False
    seasonal='multiplicative',
    seasonal_periods=12,
).fit()

forecast = fit2.forecast(12)
print(forecast)

# Valores Passados
fit2.fittedvalues.plot(style='--', color='red')
plt.show()

# Valores Futuros
fit = 12 # meses futuros
fit2.forecast(fit).plot(style='--', marker='o', color='black', legend=True)
plt.show()

# Agrupando tudo em um gr√°fico
forecast_h = 12  # meses futuros
forecast = fit2.forecast(forecast_h)

plt.plot(serie, label='Observado', color='blue')
plt.plot(fit2.fittedvalues, '--', label='Ajustado', color='red')
plt.plot(forecast, '--o', label='Previs√£o', color='black')
plt.xlabel('Data')
plt.ylabel('Quantidade')
plt.title(f'Previs√£o Holt-Winters - Produto {Produto}')
plt.legend()
plt.grid(True)
plt.show()

##############################
### M√©dia M√≥vel Simples 3M ###
##############################

import numpy as np

# PremierPet
Produto = 4001
serie = df[df['Produto'] == Produto][['Datetime', 'Quantidade']].copy()
serie.set_index('Datetime', inplace=True)

serie_MMS = serie['Quantidade'].rolling(3).mean()
print(serie_MMS)

# Plotando os resultados
plt.plot(serie['Quantidade'], label='Original', color='blue')
plt.plot(serie_MMS, label='M√©dia M√≥vel Simples 3M', color='red')
plt.xlabel("Ano", fontsize=14)
plt.ylabel("Quantidade")
plt.title(f"M√©dia M√≥vel Simples 3 Meses - Produto {Produto}")
plt.legend()
plt.grid(True)
plt.show()

################################
### M√©dia M√≥vel Ponderada 3M ###
################################

import numpy as np

# PremierPet
Produto = 4001
serie = df[df['Produto'] == Produto][['Datetime', 'Quantidade']].copy()
serie.set_index('Datetime', inplace=True)

weights = np.array([0.1, 0.3, 0.6])
serie_MMP = serie['Quantidade'].rolling(window=3).apply(lambda x: np.dot(x, weights), raw=True)
print(serie_MMP)

# Plotando os resultados
plt.plot(serie['Quantidade'], label='Original', color='blue')
plt.plot(serie_MMP, label='M√©dia M√≥vel Ponderada 3M', color='red')
plt.xlabel("Ano", fontsize=14)
plt.ylabel("Quantidade")
plt.title(f"M√©dia M√≥vel Ponderada 3 Meses - Produto {Produto}")
plt.legend()
plt.grid(True)
plt.show()

################
### LightGBM ###
################

import lightgbm as lgb
from mlforecast import MLForecast
from mlforecast.lag_transforms import ExpandingMean, RollingMean
from mlforecast.target_transforms import Differences

# PremierPet
Produto = 4002
series = df[df['Produto'] == Produto][['Datetime', 'Quantidade']].copy()
series.set_index('Datetime', inplace=True)

series = series.reset_index().rename(columns={
    'Datetime': 'ds',
    'Quantidade': 'y'
})
series['unique_id'] = Produto

models = [lgb.LGBMRegressor(random_state=0, verbosity=-1)]

# Previs√£o com MLForecast
fcst = MLForecast(
    models=models,
    freq='D',
    lags=[7, 14],
    lag_transforms={
    1: [ExpandingMean()],
    7: [RollingMean(window_size=28)]
    },
    date_features=['dayofweek'],
    target_transforms=[Differences([1])],
)

# Ajuste do modelo
fcst.fit(series)

# Valores Observado
plt.plot(series['ds'], series['y'], label='Observado', color='blue')
plt.show()

# Previs√£o Valores Futuros
n = 12 # meses futuros
forecast = fcst.predict(n)
plt.plot(forecast['ds'], forecast['LGBMRegressor'], '--', label='Previsto', color='red')
plt.show()

# Previs√£o In-sample
train = series.iloc[:-12]  # √∫ltimos 12 meses como treino
test = series.iloc[-12:] # √∫ltimos 12 meses como teste

fcst.fit(train)
n = 36
predictions = fcst.predict(n) 
plt.plot(test['ds'], test['y'], label='Teste Observado', color='Green') # 12 meses √† frente
plt.show()

# Plot
plt.figure(figsize=(12,6))
plt.plot(series['ds'], series['y'], label='Treino', color='blue')
plt.plot(test['ds'], test['y'], label='Teste', color='White', linestyle='--')
plt.plot(forecast['ds'], forecast['LGBMRegressor'], '--', label='Previsto', color='red')
plt.xlabel('Data')
plt.ylabel('Quantidade')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

####################
### AutoLightGBM ###
####################

import lightgbm as lgb
from mlforecast import MLForecast
from mlforecast.auto import AutoLightGBM, AutoXGBoost, AutoMLForecast
from mlforecast.target_transforms import Differences

###################
### AutoXGBoost ###
###################

import xgboost as xgb
from mlforecast import MLForecast
from mlforecast.auto import AutoLightGBM, AutoXGBoost, AutoMLForecast
from mlforecast.target_transforms import Differences

# PremierPet
url = "C:/Users/HenriqueSchall/OneDrive - Neo Digital Industries/nPlan-Data-Science/nPlan Forecast/Arquivos/Dados/PremieRPet/Dados_Tratados_pet.xlsx"
df = pd.read_excel(url, sheet_name="Faturamento_Historico")
print(df)

df = df.drop(columns=["Ano", "M√™s_num", "M√™s"])
df.info()
print(df)

Produto = 4002
series = df[df['Produto'] == Produto][['Datetime', 'Quantidade']].copy()
series.set_index('Datetime', inplace=True)

series = series.reset_index().rename(columns={
    'Datetime': 'ds',
    'Quantidade': 'y'
})
series['unique_id'] = Produto

fcst = MLForecast(
    models=AutoXGBoost(),
    freq='D',  # ajuste para a frequ√™ncia da s√©rie ('D' = di√°ria)
    lags=[24 * (i + 1) for i in range(7)],  # defasagens
    target_transforms=[Differences([24])]  # transforma a s√©rie, se necess√°rio
)

# Treinamento do modelo
fcst.fit(series)

# Exemplo de previs√£o para 48 passos √† frente
forecast = fcst.predict(48)

print(forecast.head())

#############################
### RandomForestRegressor ###
#############################

from sklearn.ensemble import RandomForestRegressor





